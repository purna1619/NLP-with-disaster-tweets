{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBf3_F9cBT08",
        "outputId": "9f194e5d-38cb-44c2-a36a-36b8641d15f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.10/dist-packages (0.1.73)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.10/dist-packages (from contractions) (0.0.24)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.10/dist-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.10/dist-packages (from textsearch>=0.0.21->contractions) (2.1.0)\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import re\n",
        "import logging\n",
        "from flask import Flask, request, jsonify, render_template\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from textblob import TextBlob\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from dash import dash\n",
        "import dash_core_components as dcc\n",
        "import dash_html_components as html\n",
        "from dash.dependencies import Input, Output\n",
        "import plotly.express as px\n",
        "import streamlit as st\n",
        "!pip install contractions\n",
        "from contractions import fix\n",
        "# Load the spaCy model for NLP tasks\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Initialize the Flask app\n",
        "flask_app = Flask(__name__)\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "# Load train and test datasets\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "\n",
        "# Define a function to process data in chunks\n",
        "def process_in_batches(data, batch_size=100):\n",
        "    # Create an empty list to store processed texts\n",
        "    processed_texts = []\n",
        "\n",
        "    # Process data in batches\n",
        "    for start in range(0, len(data), batch_size):\n",
        "        end = min(start + batch_size, len(data))  # Make sure we don't exceed the length\n",
        "        batch = data[start:end]\n",
        "\n",
        "        # Apply the text cleaning function to each batch\n",
        "        processed_batch = [enhanced_clean_text(text) for text in batch]\n",
        "\n",
        "        # Append the results\n",
        "        processed_texts.extend(processed_batch)\n",
        "\n",
        "    return processed_texts\n",
        "\n",
        "# Apply the batch processing to the 'text' column\n",
        "train_data_sample = train_data.sample(1000)\n",
        "\n",
        "\n",
        "# Create vectors for text data using spaCy embeddings\n",
        "def create_vec(dataframe):\n",
        "    texts = dataframe['text'].tolist()\n",
        "    vectors = [list(doc.vector) for doc in nlp.pipe(texts)]\n",
        "    vec_df = pd.DataFrame(vectors, columns=[f'vec_{i}' for i in range(len(vectors[0]))])\n",
        "    return vec_df\n",
        "\n",
        "vec_train = create_vec(train_data)\n",
        "vec_test = create_vec(test_data)\n",
        "train_data = pd.concat([train_data, vec_train], axis=1)\n",
        "test_data = pd.concat([test_data, vec_test], axis=1)\n",
        "\n",
        "# Drop unnecessary columns\n",
        "columns_to_drop = ['keyword', 'location', 'text']\n",
        "train_data.drop(columns=[col for col in columns_to_drop if col in train_data.columns], inplace=True)\n",
        "test_data.drop(columns=[col for col in columns_to_drop if col in test_data.columns], inplace=True)\n",
        "\n",
        "# Split training data\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    train_data.drop('target', axis=1), train_data['target'], test_size=0.2, random_state=42\n",
        ")\n",
        "# Convert 'vec_0' column to string type before fitting the model\n",
        "X_train['vec_0'] = X_train['vec_0'].astype(str)\n",
        "X_valid['vec_0'] = X_valid['vec_0'].astype(str) # Do the same for X_valid to avoid issues during prediction\n",
        "\n",
        "# Naive Bayes pipeline\n",
        "nb_model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
        "nb_model.fit(X_train['vec_0'], y_train)\n",
        "\n",
        "# Evaluate Naive Bayes model\n",
        "y_pred = nb_model.predict(X_valid['vec_0'])\n",
        "print(\"Naive Bayes Accuracy:\", accuracy_score(y_valid, y_pred))\n",
        "print(\"Naive Bayes Classification Report:\\n\", classification_report(y_valid, y_pred))\n",
        "\n",
        "# Build an LSTM model\n",
        "tokenizer = Tokenizer(num_words=5000, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train['vec_0'])\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train['vec_0'])\n",
        "X_valid_seq = tokenizer.texts_to_sequences(X_valid['vec_0'])\n",
        "lstm_model = Sequential([\n",
        "    Embedding(input_dim=5000, output_dim=64, input_length=100),\n",
        "    LSTM(128, return_sequences=True),\n",
        "    Dropout(0.2),\n",
        "    LSTM(64),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "max_length = 100  # Adjust this based on your data\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_length, padding='post', truncating='post')\n",
        "X_valid_pad = pad_sequences(X_valid_seq, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "\n",
        "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "lstm_model.fit(X_train_pad, y_train, validation_data=(X_valid_pad, y_valid), epochs=5, batch_size=64)\n",
        "\n",
        "\n",
        "# Flask routes\n",
        "@flask_app.route('/')\n",
        "def home():\n",
        "    return render_template('index.html')\n",
        "\n",
        "@flask_app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    input_text = request.form['text']\n",
        "    cleaned_text = enhanced_clean_text(input_text)\n",
        "    vector = [nlp(cleaned_text).vector]\n",
        "    prediction = nb_model.predict(vector)\n",
        "    return jsonify({'prediction': int(prediction[0])})\n",
        "\n",
        "@flask_app.route('/bulk_predict', methods=['POST'])\n",
        "def bulk_predict():\n",
        "    try:\n",
        "        tweets = request.json.get('tweets', [])\n",
        "        cleaned_tweets = [enhanced_clean_text(tweet) for tweet in tweets]\n",
        "        vectors = [nlp(tweet).vector for tweet in cleaned_tweets]\n",
        "        predictions = nb_model.predict(vectors)\n",
        "        return jsonify({'predictions': predictions.tolist()})\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Bulk prediction failed: {e}\")\n",
        "        return jsonify({'error': str(e)}), 500\n",
        "\n",
        "# Streamlit app for user interface\n",
        "st.title(\"Disaster Tweets Classification\")\n",
        "user_input = st.text_area(\"Enter a tweet to classify:\")\n",
        "if st.button(\"Predict\"):\n",
        "    cleaned_input = enhanced_clean_text(user_input)\n",
        "    vector = [nlp(cleaned_input).vector]\n",
        "    prediction = nb_model.predict(vector)\n",
        "    st.write(\"Prediction:\", \"Disaster\" if prediction[0] else \"Not Disaster\")\n",
        "\n",
        "# Run the Flask app\n",
        "! pip install Flask\n",
        "if __name__ == '__main__':\n",
        "    flask_app.run(debug=True)"
      ]
    }
  ]
}